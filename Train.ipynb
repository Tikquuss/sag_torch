{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "private_outputs": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "gpuClass": "standard",
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "pGxmugpoEdhI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "! git clone https://github.com/Tikquuss/sag_torch"
      ],
      "metadata": {
        "id": "mMZ3OqX1Edsw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%cd sag_torch"
      ],
      "metadata": {
        "id": "xBNNuD7kEl0t"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# %cd /content\n",
        "# !rm -r -f sag_torch"
      ],
      "metadata": {
        "id": "2Rs-dDfBEoCB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "! pip install -r requirements.txt"
      ],
      "metadata": {
        "id": "5pv6PGeREswc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import torch\n",
        "from src.modeling import Model"
      ],
      "metadata": {
        "id": "IA9iH5WrG0Tt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%load_ext tensorboard"
      ],
      "metadata": {
        "id": "KGRcxplZSFg3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Train"
      ],
      "metadata": {
        "id": "GZe3FR8eN6j7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#! wandb login 27a83be2529992fa4451956a0536d35825426b45"
      ],
      "metadata": {
        "id": "2-dfiwkVrSmu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## cmd"
      ],
      "metadata": {
        "id": "vue6uRmx8nDS"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### On run"
      ],
      "metadata": {
        "id": "rPXguvhXDSpV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "all_class = {\"int\" : int, \"str\" : str, \"float\" : float, 'bool' : bool}"
      ],
      "metadata": {
        "id": "_FcmT93Nx4In"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "str2list_type(\"int(1),str(2)\")"
      ],
      "metadata": {
        "id": "oxhWG4eNx7aF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def to_none(a):\n",
        "    return None if not a or a == \"_None_\" else a\n",
        "\n",
        "def str2list_type(s):\n",
        "    \"\"\"`int(a),str(b)` to [a, 'b']\"\"\"\n",
        "    s = to_none(s)\n",
        "    if s is None :\n",
        "        return s\n",
        "    if s:\n",
        "        params = []\n",
        "        for x in s.split(\",\"):\n",
        "            val = x.split(\"(\")\n",
        "            _class = val[0]\n",
        "            val = val[1].split(\")\")[0]\n",
        "            params.append(all_class[_class](val))\n",
        "    else:\n",
        "        params = []\n",
        "    return params"
      ],
      "metadata": {
        "id": "3zLu0ORgxyBi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "! chmod +x train.sh \n",
        "! ./train.sh "
      ],
      "metadata": {
        "id": "sGM4xbctDSIm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#! rm -r /content/log_files/0"
      ],
      "metadata": {
        "id": "l2Kh2qexDNwS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# %tensorboard --logdir /content/log_files/0/classification_wd=0.1-lr=0.001-d=0.1-opt=adam\n",
        "%tensorboard --logdir /content/log_files/0/classification_fashion_mnist/lightning_logs"
      ],
      "metadata": {
        "id": "33-1ywBPSOL_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "logdir = \"/content/log_files/0\"\n",
        "id = \"classification_wd=0.1-lr=0.001-d=0.1-opt=adam\""
      ],
      "metadata": {
        "id": "9w2nU1WvCBiG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "##\n",
        "import re\n",
        "import os \n",
        "\n",
        "def sorted_nicely(l): \n",
        "    \"\"\" Sort the given iterable in the way that humans expect.\n",
        "    https://stackoverflow.com/a/2669120/11814682\n",
        "    \"\"\" \n",
        "    convert = lambda text: int(text) if text.isdigit() else text \n",
        "    alphanum_key = lambda key: [convert(c) for c in re.split('([0-9]+)', key) ] \n",
        "    return sorted(l, key = alphanum_key)\n",
        "\n",
        "pretrained_folder = logdir + \"/\" + id\n",
        "\n",
        "#pattern = '^epoch_[0-9]+.ckpt$'\n",
        "pattern = '^epoch=[0-9]+-val_loss=[0-9]+\\.[0-9]+.ckpt$'\n",
        "\n",
        "model_files = os.listdir(pretrained_folder)\n",
        "model_files = [f for f in model_files if re.match(pattern, f)]\n",
        "model_files = sorted_nicely(model_files)\n",
        "#model_files = [\"init.ckpt\"] + model_files\n",
        "model_files = [pretrained_folder + \"/\" + f for f in model_files]\n",
        "\n",
        "L = len(model_files)\n",
        "print(L)\n",
        "\n",
        "model_files[-10:]"
      ],
      "metadata": {
        "id": "q5wyVEF9Bwjm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = Model.load_from_checkpoint(model_files[-1])"
      ],
      "metadata": {
        "id": "omzK9g2iCV-Y"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "params = torch.load(logdir + \"/params.pt\")\n",
        "data_module = torch.load(logdir+\"/data.pt\")"
      ],
      "metadata": {
        "id": "KEjYBBEJBTis"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "examples = enumerate(data_module.test_dataloader())\n",
        "batch_idx, (example_data, example_targets, indexes) = next(examples)\n",
        "batch_idx, example_data.shape"
      ],
      "metadata": {
        "id": "hG1JGI32IveY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "fig = plt.figure()\n",
        "for i in range(6):\n",
        "  plt.subplot(2,3,i+1)\n",
        "  plt.tight_layout()\n",
        "  plt.imshow(example_data[i][0], cmap='gray', interpolation='none')\n",
        "  plt.title(\"Ground Truth: {}\".format(example_targets[i]))\n",
        "  plt.xticks([])\n",
        "  plt.yticks([])\n",
        "fig"
      ],
      "metadata": {
        "id": "CmYJBe0QDW2M"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "with torch.no_grad():\n",
        "  output = model(example_data.to(model.device))"
      ],
      "metadata": {
        "id": "zyByEYeuDnBx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "fig = plt.figure()\n",
        "for i in range(6):\n",
        "  plt.subplot(2,3,i+1)\n",
        "  plt.tight_layout()\n",
        "  plt.imshow(example_data[i][0], cmap='gray', interpolation='none')\n",
        "  plt.title(\"Prediction: {}\".format(\n",
        "    output.data.max(1, keepdim=True)[1][i].item()))\n",
        "  plt.xticks([])\n",
        "  plt.yticks([])\n",
        "fig"
      ],
      "metadata": {
        "id": "j52qO3ToDbnM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### Multiple run "
      ],
      "metadata": {
        "id": "vNrPMWndDVwM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "! chmod +x train_loop.sh\n",
        "! ./train_loop.sh "
      ],
      "metadata": {
        "id": "XNNrGVDa8qZ-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Without cmd (see multiple_runs.py) : Allows to visualize directly the embedding evolution in the notebook output"
      ],
      "metadata": {
        "id": "YUJyQr3x8SOb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from src.utils import AttrDict\n",
        "from src.dataset import LMLightningDataModule\n",
        "from src.trainer import train"
      ],
      "metadata": {
        "id": "6FA9Q0jRAUOa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "weight_decay=0.0\n",
        "lr=0.001\n",
        "dropout=0.5\n",
        "opt=\"adam\"\n",
        "group_name=f\"wd={weight_decay}-lr={lr}-d={dropout}-opt={opt}\"\n",
        "\n",
        "random_seed=0\n",
        "log_dir=\"../log_files\"\n",
        "task = \"classification\"\n",
        "dataset_name=\"mnist\"\n",
        "\n",
        "opt=f\"{opt},weight_decay={weight_decay},beta1=0.9,beta2=0.99,eps=0.00000001\"\n",
        "\n",
        "opt=\"sag\"\n",
        "opt=f\"{opt},weight_decay={weight_decay}\"\n",
        "\n",
        "params = AttrDict({\n",
        "    ### Main parameters\n",
        "    \"task\" : task,\n",
        "    \"exp_id\" : f\"{task}_{group_name}\",\n",
        "    \"log_dir\" : f\"{log_dir}/{random_seed}\",\n",
        "\n",
        "    ### Model\n",
        "    \"hidden_dim\" : 512,  \n",
        "\t  \"dropout\" : dropout,\n",
        "\n",
        "    ### Dataset\n",
        "    \"dataset_name\":dataset_name,\n",
        "    \"train_batch_size\" : 512,\n",
        "    \"val_batch_size\" : 10000,\n",
        "\n",
        "    ### Optimizer\n",
        "    \"optimizer\" : opt,\n",
        "    \"lr\" : lr,\n",
        "\n",
        "    ### LR Scheduler\n",
        "    \"lr_scheduler\" : None,\n",
        "    #\"lr_scheduler\" : \"reduce_lr_on_plateau,factor=0.2,patience=20,min_lr=0.00005,mode=min,monitor=val_loss\",\n",
        "    \n",
        "    ### Training\n",
        "    \"max_epochs\" : 10, \n",
        "    \"validation_metrics\" : \"val_loss\",\n",
        "    \"checkpoint_path\" : None, \n",
        "    \"model_name\": \"\", \n",
        "    \"every_n_epochs\":1, \n",
        "    \"every_n_epochs_show\":1, \n",
        "    \"early_stopping_patience\":1e9, \n",
        "    \"save_top_k\":-1,\n",
        "\n",
        "    # Wandb \n",
        "    \"use_wandb\" : False,\n",
        "    \"wandb_entity\" : \"grokking_ppsp\",\n",
        "    \"wandb_project\" : f\"dataset={dataset_name}-task={task}\",\n",
        "    \"group_name\" : group_name,\n",
        "\n",
        "    \"group_vars\" : None,\n",
        "    \n",
        "    # Devices & Seed\n",
        "    \"accelerator\" : \"auto\",\n",
        "    \"devices\" : \"auto\",\n",
        "    \"random_seed\": random_seed,\n",
        "\n",
        "    ### Early_stopping (for grokking) : Stop the training `patience` epochs after the `metric` has reached the value `metric_threshold` \n",
        "    #\"early_stopping_grokking\" : None,\n",
        "    \"early_stopping_grokking\" : \"patience=int(1000),metric=str(val_acc),metric_threshold=float(90.0)\",\n",
        "\n",
        "})\n",
        "\n",
        "params.regression = params.task == \"regression\"\n",
        "data_module = LMLightningDataModule(\n",
        "    dataset_name = params.dataset_name,\n",
        "    train_batch_size = params.train_batch_size,\n",
        "    val_batch_size = params.val_batch_size,\n",
        "    #num_workers = params.num_workers,\n",
        ")\n",
        "setattr(params, \"data_infos\", data_module.data_infos)"
      ],
      "metadata": {
        "id": "Jgbpjf1x8KXP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model, result = train(params, data_module)"
      ],
      "metadata": {
        "id": "32NMaOIFBw-v"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### On run"
      ],
      "metadata": {
        "id": "-NRGCIlA9bhY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model, result = train(params, train_loader, val_loader)"
      ],
      "metadata": {
        "id": "sThynjEc9dub"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%tensorboard --logdir /content/log_files/0/classification_tdf=80-wd=0.0-r_lr=0.001-d_lr=0.001-r_d=0.0-d_d=0.0-opt=adam/lightning_logs"
      ],
      "metadata": {
        "id": "K9nww6oiSJ9X"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#! rm -r /content/log_files/0"
      ],
      "metadata": {
        "id": "6lcvELg7JDU6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### Multiple run (for phase diagram) : see multiple_runs.py or train_parallel.py"
      ],
      "metadata": {
        "id": "Ed9z7mmMbTka"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#! python multiple_runs.py\n",
        "#! python train_parallel.py --parallel False"
      ],
      "metadata": {
        "id": "LDzE4RFopzaf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "\n",
        "from multiple_runs import plot_results, itertools\n",
        "from src.utils import get_group_name"
      ],
      "metadata": {
        "id": "dpflv6G5Js2f"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#decoder_lrs = representation_lrs = [1e-2, 1e-3] \n",
        "decoder_lrs = representation_lrs = np.linspace(start=1e-1, stop=1e-5, num=4)\n",
        "\n",
        "weight_decays = list(range(5))\n",
        "#weight_decays =  np.linspace(start=0, stop=20, num=21)\n",
        "\n",
        "flag = False # if True, decoder_lrs if True, else weight_decays\n",
        "if flag : s = \"decoder_lr\"\n",
        "else : s = \"weight_decay\"\n",
        "\n",
        "tmps = decoder_lrs if flag else weight_decays\n",
        "\n",
        "print(representation_lrs, decoder_lrs if flag else weight_decays)"
      ],
      "metadata": {
        "id": "I4-isRL9KwKT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model_dict = {}\n",
        "i = 0\n",
        "for a, b in itertools.product(representation_lrs, tmps) :\n",
        "\n",
        "    params[\"representation_lr\"] = a \n",
        "    if flag : params[s] = b\n",
        "    else : params[\"optimizer\"] = params[\"optimizer\"].replace(f\"{s}={weight_decay}\", f\"{s}={b}\")\n",
        "  \n",
        "    name = f\"representation_lr={a}, {s}={b}\"\n",
        "    params.exp_id = name\n",
        "    \n",
        "    #group_vars = GROUP_VARS + [\"representation_lr\", s]\n",
        "    group_vars = [\"representation_lr\", s]\n",
        "    group_vars = list(set(group_vars))\n",
        "    params[\"group_name\"] = get_group_name(params, group_vars = group_vars)\n",
        "    \n",
        "    print(\"*\"*10, i, name, \"*\"*10)\n",
        "    i+=1\n",
        "\n",
        "    model, result = None, None # train(params, train_loader, val_loader)\n",
        "    \n",
        "    model_dict[name] = {\"model\": model, \"result\": result}"
      ],
      "metadata": {
        "id": "f9U3jz-bIcB-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(model_dict.keys())"
      ],
      "metadata": {
        "id": "R4REND4yK15u"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "val_loss = [model_dict[k][\"result\"][\"val\"][\"val_loss\"] for k in model_dict]\n",
        "val_acc = [model_dict[k][\"result\"][\"val\"].get(\"val_acc\", 0) for k in model_dict]\n",
        "print(val_loss, val_acc)"
      ],
      "metadata": {
        "id": "u0s6SL3QLX-E"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plot_results(params, model_dict, \n",
        "    hparms_1 = representation_lrs, hparms_2 = decoder_lrs if flag else weight_decays,\n",
        "    s1 = 'representation_lr', s2 = s\n",
        ")"
      ],
      "metadata": {
        "id": "D_vDlEXELV1k"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}