{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [
        "vNrPMWndDVwM",
        "-NRGCIlA9bhY",
        "Ed9z7mmMbTka"
      ],
      "private_outputs": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "pGxmugpoEdhI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "! git clone https://github.com/Tikquuss/sag_torch"
      ],
      "metadata": {
        "id": "mMZ3OqX1Edsw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%cd sag_torch"
      ],
      "metadata": {
        "id": "xBNNuD7kEl0t"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# %cd /content\n",
        "# !rm -r -f sag_torch"
      ],
      "metadata": {
        "id": "2Rs-dDfBEoCB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "! pip install -r requirements.txt"
      ],
      "metadata": {
        "id": "5pv6PGeREswc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import torch\n",
        "from src.modeling import Model\n",
        "from src.dataset import TORCH_SET"
      ],
      "metadata": {
        "id": "IA9iH5WrG0Tt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%load_ext tensorboard"
      ],
      "metadata": {
        "id": "KGRcxplZSFg3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Train"
      ],
      "metadata": {
        "id": "GZe3FR8eN6j7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#! wandb login 27a83be2529992fa4451956a0536d35825426b45"
      ],
      "metadata": {
        "id": "2-dfiwkVrSmu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## cmd"
      ],
      "metadata": {
        "id": "vue6uRmx8nDS"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### On run"
      ],
      "metadata": {
        "id": "rPXguvhXDSpV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "! chmod +x train.sh \n",
        "! ./train.sh "
      ],
      "metadata": {
        "id": "sGM4xbctDSIm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "! rm -r /content/log_files"
      ],
      "metadata": {
        "id": "l2Kh2qexDNwS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# %tensorboard --logdir /content/log_files/0/classification_wd=0.1-lr=0.001-d=0.1-opt=adam\n",
        "%tensorboard --logdir /content/log_files/0/iris/wd=0.0-lr=0.001-d=0.5-opt=adam/lightning_logs"
      ],
      "metadata": {
        "id": "33-1ywBPSOL_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "logdir = \"/content/log_files/0\"\n",
        "id = \"/iris/wd=0.0-lr=0.001-d=0.5-opt=adam\"\n",
        "logdir += \"/\" + id"
      ],
      "metadata": {
        "id": "9w2nU1WvCBiG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "##\n",
        "import re\n",
        "import os \n",
        "\n",
        "def sorted_nicely(l): \n",
        "    \"\"\" Sort the given iterable in the way that humans expect.\n",
        "    https://stackoverflow.com/a/2669120/11814682\n",
        "    \"\"\" \n",
        "    convert = lambda text: int(text) if text.isdigit() else text \n",
        "    alphanum_key = lambda key: [convert(c) for c in re.split('([0-9]+)', key) ] \n",
        "    return sorted(l, key = alphanum_key)\n",
        "\n",
        "pretrained_folder = logdir\n",
        "\n",
        "#pattern = '^epoch_[0-9]+.ckpt$'\n",
        "pattern = '^epoch=[0-9]+-val_loss=[0-9]+\\.[0-9]+.ckpt$'\n",
        "\n",
        "model_files = os.listdir(pretrained_folder)\n",
        "model_files = [f for f in model_files if re.match(pattern, f)]\n",
        "model_files = sorted_nicely(model_files)\n",
        "#model_files = [\"init.ckpt\"] + model_files\n",
        "model_files = [pretrained_folder + \"/\" + f for f in model_files]\n",
        "\n",
        "L = len(model_files)\n",
        "print(L)\n",
        "\n",
        "model_files[-10:]"
      ],
      "metadata": {
        "id": "q5wyVEF9Bwjm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = Model.load_from_checkpoint(model_files[-1])"
      ],
      "metadata": {
        "id": "omzK9g2iCV-Y"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "params = torch.load(logdir + \"/params.pt\")\n",
        "data_module = torch.load(logdir+\"/data.pt\")"
      ],
      "metadata": {
        "id": "KEjYBBEJBTis"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "examples = enumerate(data_module.test_dataloader())\n",
        "batch_idx, (example_data, example_targets, indexes) = next(examples)\n",
        "batch_idx, example_data.shape"
      ],
      "metadata": {
        "id": "hG1JGI32IveY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "if params.dataset_name in TORCH_SET :\n",
        "    import matplotlib.pyplot as plt\n",
        "\n",
        "    fig = plt.figure()\n",
        "    for i in range(6):\n",
        "      plt.subplot(2,3,i+1)\n",
        "      plt.tight_layout()\n",
        "      plt.imshow(example_data[i][0], cmap='gray', interpolation='none')\n",
        "      plt.title(\"Ground Truth: {}\".format(example_targets[i]))\n",
        "      plt.xticks([])\n",
        "      plt.yticks([])\n",
        "    fig"
      ],
      "metadata": {
        "id": "CmYJBe0QDW2M"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "with torch.no_grad():\n",
        "  output = model(example_data.to(model.device))"
      ],
      "metadata": {
        "id": "zyByEYeuDnBx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "if params.dataset_name in TORCH_SET :\n",
        "    fig = plt.figure()\n",
        "    for i in range(6):\n",
        "      plt.subplot(2,3,i+1)\n",
        "      plt.tight_layout()\n",
        "      plt.imshow(example_data[i][0], cmap='gray', interpolation='none')\n",
        "      plt.title(\"Prediction: {}\".format(\n",
        "        output.data.max(1, keepdim=True)[1][i].item()))\n",
        "      plt.xticks([])\n",
        "      plt.yticks([])\n",
        "    fig"
      ],
      "metadata": {
        "id": "j52qO3ToDbnM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### Multiple run "
      ],
      "metadata": {
        "id": "vNrPMWndDVwM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "! chmod +x train_loop.sh\n",
        "! ./train_loop.sh "
      ],
      "metadata": {
        "id": "XNNrGVDa8qZ-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Without cmd (see multiple_runs.py) : Allows to visualize directly the embedding evolution in the notebook output"
      ],
      "metadata": {
        "id": "YUJyQr3x8SOb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pytorch_lightning as pl\n",
        "import torch\n",
        "\n",
        "from src.utils import AttrDict\n",
        "from src.dataset import LMLightningDataModule\n",
        "from src.trainer import train"
      ],
      "metadata": {
        "id": "6FA9Q0jRAUOa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "weight_decay=0.0\n",
        "lr=0.001\n",
        "dropout=0.5\n",
        "opt=\"adam\"\n",
        "group_name=f\"wd={weight_decay}-lr={lr}-d={dropout}-opt={opt}\"\n",
        "\n",
        "random_seed=0\n",
        "log_dir=\"../log_files\"\n",
        "\n",
        "dataset_name=\"iris\"\n",
        "train_pct=80\n",
        "\n",
        "#val_metric=\"val_acc\"\n",
        "val_metric=\"val_loss\"\n",
        "\n",
        "opt=f\"{opt},weight_decay={weight_decay},beta1=0.9,beta2=0.99,eps=0.00000001\"\n",
        "opt=\"sag\"\n",
        "opt=f\"sgd,weight_decay={weight_decay}\"\n",
        "opt=f\"sag,weight_decay={weight_decay},batch_mode=False,init_y_i=True\"\n",
        "\n",
        "\n",
        "params = AttrDict({\n",
        "    ### Main parameters\n",
        "    \"exp_id\" : f\"{dataset_name}\",\n",
        "    \"log_dir\" : f\"{log_dir}\",\n",
        "\n",
        "    ### Model\n",
        "\t  \"c_out\" :  [10, 10],\n",
        "\t  \"hidden_dim\" :  [50],\n",
        "\t  \"kernel_size\" : [5],\n",
        "\t  \"kernel_size_maxPool\" : 2,\n",
        "\t  \"dropout\"  : dropout,\n",
        "\n",
        "    ### Dataset\n",
        "    \"dataset_name\":dataset_name,\n",
        "    \"train_batch_size\" : 512,\n",
        "    \"val_batch_size\" : 512,\n",
        "\t  \"train_pct\" : train_pct,\n",
        "\t  \"val_pct\" : 100,\n",
        "\n",
        "    ### Optimizer\n",
        "    \"optimizer\" : opt,\n",
        "    \"lr\" : lr,\n",
        "\n",
        "    ### LR Scheduler\n",
        "    \"lr_scheduler\" : None,\n",
        "    #\"lr_scheduler\" : \"reduce_lr_on_plateau,factor=0.2,patience=20,min_lr=0.00005,mode=min,monitor=val_loss\",\n",
        "    \n",
        "    ### Training\n",
        "    \"max_epochs\" : 10, \n",
        "    \"validation_metrics\" : \"val_loss\",\n",
        "    \"checkpoint_path\" : None, \n",
        "    \"model_name\": \"\", \n",
        "    \"every_n_epochs\":1, \n",
        "    \"every_n_epochs_show\":1, \n",
        "    \"early_stopping_patience\":1e9, \n",
        "    \"save_top_k\":-1,\n",
        "\n",
        "    # Wandb \n",
        "    \"use_wandb\" : False,\n",
        "    \"wandb_entity\" : \"grokking_ppsp\",\n",
        "    \"wandb_project\" : f\"dataset={dataset_name}\",\n",
        "    \"group_name\" : group_name,\n",
        "\n",
        "    \"group_vars\" : None,\n",
        "    \n",
        "    # Devices & Seed\n",
        "    \"accelerator\" : \"auto\",\n",
        "    \"devices\" : \"auto\",\n",
        "    \"random_seed\": random_seed,\n",
        "\n",
        "    ### Early_stopping (for grokking) : Stop the training `patience` epochs after the `metric` has reached the value `metric_threshold` \n",
        "    #\"early_stopping_grokking\" : None,\n",
        "    \"early_stopping_grokking\" : f\"patience=int(1000),metric=str({val_metric}),metric_threshold=float(90.0)\",\n",
        "\n",
        "})\n",
        "\n",
        "pl.seed_everything(params.random_seed, workers=True)\n",
        "# Ensure that all operations are deterministic on GPU (if used) for reproducibility\n",
        "torch.backends.cudnn.determinstic = True\n",
        "torch.backends.cudnn.benchmark = False\n",
        "\n",
        "root_dir = os.path.join(params.log_dir, params.exp_id, params.group_name, str(params.random_seed)) \n",
        "os.makedirs(root_dir, exist_ok=True)\n",
        "\n",
        "data_module = LMLightningDataModule(\n",
        "    dataset_name = params.dataset_name,\n",
        "    train_batch_size = params.train_batch_size,\n",
        "    val_batch_size = params.val_batch_size,\n",
        "    train_pct = params.train_pct,\n",
        "    val_pct = params.val_pct,\n",
        "    data_path = params.log_dir + \"/data\",\n",
        "    #num_workers = params.num_workers,\n",
        ")\n",
        "setattr(params, \"data_infos\", data_module.data_infos)\n",
        "setattr(params, \"train_dataset\", data_module.train_dataset)"
      ],
      "metadata": {
        "id": "Jgbpjf1x8KXP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### On run"
      ],
      "metadata": {
        "id": "-NRGCIlA9bhY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model, result = train(params, data_module, root_dir)"
      ],
      "metadata": {
        "id": "sThynjEc9dub"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%tensorboard --logdir /content/log_files/0/classification_tdf=80-wd=0.0-r_lr=0.001-d_lr=0.001-r_d=0.0-d_d=0.0-opt=adam/lightning_logs"
      ],
      "metadata": {
        "id": "K9nww6oiSJ9X"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#! rm -r /content/log_files/0"
      ],
      "metadata": {
        "id": "6lcvELg7JDU6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### Multiple run (for phase diagram) : see multiple_runs.py or train_parallel.py"
      ],
      "metadata": {
        "id": "Ed9z7mmMbTka"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "! python multiple_runs.py"
      ],
      "metadata": {
        "id": "LDzE4RFopzaf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "\n",
        "from multiple_runs import plot_results, itertools\n",
        "from src.utils import get_group_name"
      ],
      "metadata": {
        "id": "dpflv6G5Js2f"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "lrs = [1e-2, 1e-3, 1e-4, 1e-5] \n",
        "#lrs = np.linspace(start=1e-1, stop=1e-5, num=10)\n",
        "\n",
        "weight_decays = [0, 1]\n",
        "#weight_decays = list(range(20))\n",
        "#weight_decays =  np.linspace(start=0, stop=20, num=21)\n",
        "\n",
        "s = \"weight_decay\"\n",
        "assert s in params[\"optimizer\"]\n",
        "print(lrs, weight_decays)"
      ],
      "metadata": {
        "id": "I4-isRL9KwKT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model_dict = {}\n",
        "i = 0\n",
        "for a, b in itertools.product(lrs, weight_decays) :\n",
        "    params[\"lr\"] = a \n",
        "    params[\"optimizer\"] = params[\"optimizer\"].replace(f\"{s}={weight_decay}\", f\"{s}={b}\")\n",
        "    \n",
        "    name = f\"lr={a}, {s}={b}\"\n",
        "    params.exp_id = name\n",
        "        \n",
        "    #group_vars = GROUP_VARS + [\"lr\", s]\n",
        "    group_vars = [\"lr\", s]\n",
        "    group_vars = list(set(group_vars))\n",
        "    setattr(params, s, b)\n",
        "    params[\"group_name\"] = get_group_name(params, group_vars = group_vars)\n",
        "        \n",
        "    print(\"*\"*10, i, name, \"*\"*10)\n",
        "    i+=1\n",
        "\n",
        "    model, result = train(params, data_module, root_dir)\n",
        "        \n",
        "    model_dict[name] = {\"model\": model, \"result\": result}"
      ],
      "metadata": {
        "id": "f9U3jz-bIcB-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(model_dict.keys())"
      ],
      "metadata": {
        "id": "R4REND4yK15u"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "val_loss = [model_dict[k][\"result\"][\"val\"][\"val_loss\"] for k in model_dict]\n",
        "val_acc = [model_dict[k][\"result\"][\"val\"].get(\"val_acc\", 0) for k in model_dict]\n",
        "print(val_loss, val_acc)"
      ],
      "metadata": {
        "id": "u0s6SL3QLX-E"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plot_results(params, model_dict, \n",
        "    hparms_1 = lrs, hparms_2 = weight_decays,\n",
        "    s1 = 'lr', s2 = s\n",
        ")"
      ],
      "metadata": {
        "id": "JjPuF7I5Hgxf"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}