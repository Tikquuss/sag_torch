{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "pGxmugpoEdhI"
   },
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "mMZ3OqX1Edsw"
   },
   "outputs": [],
   "source": [
    "#! git clone https://github.com/Tikquuss/sag_torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "xBNNuD7kEl0t"
   },
   "outputs": [],
   "source": [
    "#%cd sag_torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "5pv6PGeREswc"
   },
   "outputs": [],
   "source": [
    "#! pip install -r requirements.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "IA9iH5WrG0Tt"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "from src.modeling import Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "KGRcxplZSFg3"
   },
   "outputs": [],
   "source": [
    "%load_ext tensorboard"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "GZe3FR8eN6j7"
   },
   "source": [
    "# Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "2-dfiwkVrSmu"
   },
   "outputs": [],
   "source": [
    "#! wandb login $som_key"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "vue6uRmx8nDS"
   },
   "source": [
    "## cmd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "rPXguvhXDSpV"
   },
   "source": [
    "##### On run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "sGM4xbctDSIm"
   },
   "outputs": [],
   "source": [
    "! chmod +x train.sh \n",
    "! ./train.sh "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "33-1ywBPSOL_"
   },
   "outputs": [],
   "source": [
    "%tensorboard --logdir /content/log_files/0/classification_tdf=80-wd=0.0-r_lr=0.001-d_lr=0.001-r_d=0.0-d_d=0.0-opt=adam/lightning_logs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "zDC_CjBcDutA"
   },
   "outputs": [],
   "source": [
    "pretrained_filename = \"/content/log_files/0/classification_tdf=80-wd=0.0-r_lr=0.001-d_lr=0.001-r_d=0.0-d_d=0.0-opt=adam/epoch=1-val_loss=5.2339.ckpt\"\n",
    "model = Model.load_from_checkpoint(pretrained_filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "hG1JGI32IveY"
   },
   "outputs": [],
   "source": [
    "#! rm -r /content/log_files/0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "vNrPMWndDVwM"
   },
   "source": [
    "##### Multiple run (for phase diagram)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "XNNrGVDa8qZ-"
   },
   "outputs": [],
   "source": [
    "! chmod +x train_loop.sh\n",
    "! ./train_loop.sh "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "YUJyQr3x8SOb"
   },
   "source": [
    "## Without cmd (see multiple_runs.py) : Allows to visualize directly the embedding evolution in the notebook output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "6FA9Q0jRAUOa"
   },
   "outputs": [],
   "source": [
    "from src.utils import AttrDict\n",
    "from src.dataset import get_dataloader\n",
    "from src.trainer import train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Jgbpjf1x8KXP"
   },
   "outputs": [],
   "source": [
    "train_pct=80\n",
    "weight_decay=0.0\n",
    "representation_lr=0.001\n",
    "decoder_lr=0.001\n",
    "representation_dropout=0.0\n",
    "decoder_dropout=0.0\n",
    "opt=\"adam\"\n",
    "\n",
    "group_name=f\"tdf={train_pct}-wd={weight_decay}-r_lr={representation_lr}-d_lr={decoder_lr}-r_d={representation_dropout}-d_d={decoder_dropout}-opt={opt}\"\n",
    "\n",
    "random_seed=0\n",
    "operator=\"+\"\n",
    "modular=False\n",
    "\n",
    "log_dir=\"../log_files\"\n",
    "\n",
    "p = 100\n",
    "task = \"classification\"\n",
    "\n",
    "params = AttrDict({\n",
    "    ### Main parameters\n",
    "    \"task\" : task,\n",
    "    \"exp_id\" : f\"{task}_{group_name}\",\n",
    "    \"log_dir\" : f\"{log_dir}/{random_seed}\",\n",
    "\n",
    "    ### Model\n",
    "    \"emb_dim\" : 256, \n",
    "    \"hidden_dim\" : 512,  \n",
    "    \"n_layers\" : 1,\n",
    "\t\"representation_dropout\" : representation_dropout,\n",
    "\t\"decoder_dropout\" : decoder_dropout,\n",
    "    \"pad_index\" : None, \n",
    "    \"p\" : p, \n",
    "\n",
    "    ### Dataset\n",
    "    \"operator\" : operator, \n",
    "    \"modular\" : modular,\n",
    "    \"train_pct\" : train_pct,\n",
    "    \"batch_size\" : 512,\n",
    "\n",
    "    ### Optimizer\n",
    "    \"optimizer\" : f\"{opt},weight_decay={weight_decay},beta1=0.9,beta2=0.99,eps=0.00000001\",\n",
    "    \"representation_lr\" : representation_lr,\n",
    "    \"decoder_lr\" : decoder_lr,\n",
    "\n",
    "    ### LR Scheduler\n",
    "    \"lr_scheduler\" : None,\n",
    "    #\"lr_scheduler\" : \"reduce_lr_on_plateau,factor=0.2,patience=20,min_lr=0.00005,mode=min,monitor=val_loss\",\n",
    "    \n",
    "    ### Training\n",
    "    \"max_epochs\" : 2, \n",
    "    \"validation_metrics\" : \"val_loss\",\n",
    "    \"checkpoint_path\" : None, \n",
    "    \"model_name\": \"\", \n",
    "    \"every_n_epochs\":1, \n",
    "    \"every_n_epochs_show\":1, \n",
    "    \"early_stopping_patience\":1e9, \n",
    "    \"save_top_k\":-1,\n",
    "\n",
    "    # Wandb \n",
    "    \"use_wandb\" : False,\n",
    "\t\"wandb_entity\" : \"grokking_ppsp\",\n",
    "\t\"wandb_project\" : f\"toy_model_grokking_op={operator}-p={p}-task={task}-mod={modular}\",\n",
    "    \"group_name\" : group_name,\n",
    "\n",
    "    \"group_vars\" : None,\n",
    "\n",
    "    ### Intrinsic Dimension Estimation\n",
    "    #\"ID_params\" : {},\n",
    "    #\"ID_params\": {\"method\" : \"mle\", \"k\":2},\n",
    "    \"ID_params\": {\"method\" : \"twonn\"},\n",
    "    \n",
    "    # Devices & Seed\n",
    "    \"accelerator\" : \"auto\",\n",
    "    \"devices\" : \"auto\",\n",
    "    \"random_seed\": random_seed,\n",
    "\n",
    "    ### Early_stopping (for grokking) : Stop the training `patience` epochs after the `metric` has reached the value `metric_threshold` \n",
    "    #\"early_stopping_grokking\" : None,\n",
    "    \"early_stopping_grokking\" : \"patience=int(1000),metric=str(val_acc),metric_threshold=float(90.0)\",\n",
    "\n",
    "})\n",
    "params[\"weight_decay\"] = weight_decay\n",
    "params[\"regression\"] = task == \"regression\"\n",
    "train_loader, val_loader, dataloader, data_infos = get_dataloader(\n",
    "    p, train_pct, regression = params.regression, operator=params.operator, \n",
    "    modular = params.modular, batch_size=params.batch_size, num_workers=2\n",
    ")\n",
    "print(data_infos)\n",
    "params[\"data_infos\"] = data_infos"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-NRGCIlA9bhY"
   },
   "source": [
    "##### On run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "sThynjEc9dub"
   },
   "outputs": [],
   "source": [
    "model, result = train(params, train_loader, val_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "K9nww6oiSJ9X"
   },
   "outputs": [],
   "source": [
    "%tensorboard --logdir /content/log_files/0/classification_tdf=80-wd=0.0-r_lr=0.001-d_lr=0.001-r_d=0.0-d_d=0.0-opt=adam/lightning_logs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "6lcvELg7JDU6"
   },
   "outputs": [],
   "source": [
    "#! rm -r /content/log_files/0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Ed9z7mmMbTka"
   },
   "source": [
    "##### Multiple run (for phase diagram) : see multiple_runs.py or train_parallel.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "LDzE4RFopzaf"
   },
   "outputs": [],
   "source": [
    "#! python multiple_runs.py\n",
    "#! python train_parallel.py --parallel False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "dpflv6G5Js2f"
   },
   "outputs": [],
   "source": [
    "from multiple_runs import plot_results, itertools\n",
    "from src.utils import get_group_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "I4-isRL9KwKT"
   },
   "outputs": [],
   "source": [
    "decoder_lrs = representation_lrs = [1e-2, 1e-3] \n",
    "#decoder_lrs = representation_lrs = np.linspace(start=1e-1, stop=1e-5, num=10)\n",
    "\n",
    "weight_decays = list(range(20))\n",
    "#weight_decays =  np.linspace(start=0, stop=20, num=21)\n",
    "\n",
    "flag = True # if True, decoder_lrs if True, else weight_decays\n",
    "if flag : s = \"decoder_lr\"\n",
    "else : s = \"weight_decay\"\n",
    "print(representation_lrs, decoder_lrs if flag else weight_decays)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "f9U3jz-bIcB-"
   },
   "outputs": [],
   "source": [
    "model_dict = {}\n",
    "i = 0\n",
    "for a, b in itertools.product(representation_lrs, decoder_lrs if flag else weight_decays) :\n",
    "\n",
    "    params[\"representation_lr\"] = a \n",
    "    if flag : params[s] = b\n",
    "    else : params[\"optimizer\"] = params[\"optimizer\"].replace(f\"{s}={weight_decay}\", f\"{s}={b}\")\n",
    "  \n",
    "    name = f\"representation_lr={a}, {s}={b}\"\n",
    "    params.exp_id = name\n",
    "    \n",
    "    #group_vars = GROUP_VARS + [\"representation_lr\", s]\n",
    "    group_vars = [\"representation_lr\", s]\n",
    "    group_vars = list(set(group_vars))\n",
    "    params[\"group_name\"] = get_group_name(params, group_vars = group_vars)\n",
    "    \n",
    "    print(\"*\"*10, i, name, \"*\"*10)\n",
    "    i+=1\n",
    "\n",
    "    model, result = train(params, train_loader, val_loader)\n",
    "    \n",
    "    model_dict[name] = {\"model\": model, \"result\": result}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "R4REND4yK15u"
   },
   "outputs": [],
   "source": [
    "print(model_dict.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "u0s6SL3QLX-E"
   },
   "outputs": [],
   "source": [
    "val_loss = [model_dict[k][\"result\"][\"val\"][\"val_loss\"] for k in model_dict]\n",
    "val_acc = [model_dict[k][\"result\"][\"val\"].get(\"val_acc\", 0) for k in model_dict]\n",
    "print(val_loss, val_acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "D_vDlEXELV1k"
   },
   "outputs": [],
   "source": [
    "plot_results(params, model_dict, \n",
    "    hparms_1 = representation_lrs, hparms_2 = decoder_lrs if flag else weight_decays,\n",
    "    s1 = 'representation_lr', s2 = s\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "sqMC9huSmGSn"
   },
   "outputs": [],
   "source": [
    "# for a, b in itertools.product(representation_lrs, decoder_lrs if flag else weight_decays) :\n",
    "#     name = f\"representation_lr={a}, {s}={b}\"\n",
    "#     model = model_dict[name][\"model\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Q8yoO9FIMRuE"
   },
   "source": [
    "## Visualize embedding 2&3D with plotly (This and the following sections only need `model`)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "swC9YZ4YND4Y"
   },
   "outputs": [],
   "source": [
    "#_ = display_pca_scatterplot(model.hparams.p, model, dim=3)\n",
    "_ = display_pca_scatterplot(model.hparams.p, model, dim=2, title=\"Embeddings\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "PneNJyMjNGAc"
   },
   "outputs": [],
   "source": [
    "word_vectors = model.mlp[-1].weight\n",
    "_ = display_pca_scatterplot(word_vectors.size(0), model, word_vectors = word_vectors, dim=2, title = f\"last_layer_weight\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_xEld2ZhNKJF"
   },
   "source": [
    "## Video animation (visualize the evolution of embedding during training)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "6jywyMXpNcfk"
   },
   "outputs": [],
   "source": [
    "root_dir = os.path.join(model.hparams.log_dir, model.hparams.exp_id, \"images\")\n",
    "for dirname in os.listdir(root_dir) :\n",
    "    image_folder = os.path.join(root_dir, dirname)\n",
    "    if os.path.isdir(image_folder):\n",
    "        print(image_folder)\n",
    "        try :\n",
    "            video_path = os.path.join(model.hparams.log_dir, model.hparams.exp_id, f'{dirname}.avi')\n",
    "            images_to_vidoe(image_folder, video_path, format=\"png\")\n",
    "            print(video_path)\n",
    "        except IndexError: #list index out of range\n",
    "            print(\"Error\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "akBzjYOpNPYR"
   },
   "outputs": [],
   "source": [
    "root_dir = os.path.join(model.hparams.log_dir, model.hparams.exp_id, \"images\")\n",
    "video_path = os.path.join(model.hparams.log_dir, model.hparams.exp_id, f'grid.avi')\n",
    "print(video_path)\n",
    "images_to_vidoe(root_dir, video_path, format=\"png\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "iyTwt9pbNh9i"
   },
   "source": [
    "## Visualize the learned set of embeddings (if embed_dim=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "zPG9SR8cNpNo"
   },
   "outputs": [],
   "source": [
    "if model.hparams.emb_dim == 2 :\n",
    "    img = visualize_embeddings_good(model, A = None, B = None, N = 500, \n",
    "                                    interpolation=None,\n",
    "                                    #interpolation='hermite',\n",
    "                                    figsize=(5,5), title = \"learned_set_of_embeddings\",\n",
    "                                    save_to='/content/learned_set_of_embeddings.png'\n",
    "                                    ) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "3DvsZW-dMwsO"
   },
   "source": [
    "## Visualize embedding 2D (good)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "RtEbddgvOq-R"
   },
   "outputs": [],
   "source": [
    "# !pip install folium==0.2.1\n",
    "# !pip install pdflatex\n",
    "# !sudo apt-get install texlive-latex-recommended \n",
    "# !sudo apt install texlive-latex-extra\n",
    "# !sudo apt install dvipng"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "GW3x74gQQX7u"
   },
   "outputs": [],
   "source": [
    "# ! python src/analyze_embedding.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "CS0z9KS-Riu6"
   },
   "outputs": [],
   "source": [
    "from src.analyze_embedding import display_pca_scatterplot_simple\n",
    "import numpy as np\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "r8q2K83MRyDR"
   },
   "outputs": [],
   "source": [
    "save_path = os.path.join(model.hparams.log_dir, model.hparams.exp_id, \"Visualize_embedding\")\n",
    "os.makedirs(save_path, exist_ok=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "oMzYAAh1Ss-0"
   },
   "source": [
    "### Embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "jBLkR-CBOeug"
   },
   "outputs": [],
   "source": [
    "data_dim, words = display_pca_scatterplot(model.hparams.p, model, dim=2, return_data = True)\n",
    "#word_vectors = model.embeddings.weight\n",
    "#data_dim, words = display_pca_scatterplot(model.hparams.p, model, word_vectors = word_vectors, dim=2, return_data = True)\n",
    "\n",
    "N=data_dim.shape[0] # \n",
    "filename = f\"{model.hparams.p}_structured_embedding\"\n",
    "display_pca_scatterplot_simple(data_dim, words, N, save_path, filename, \n",
    "                               #plot_line = True,\n",
    "                               plot_line = False, \n",
    "                               cmap='viridis', eps = 0.01)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "buN6rwDQSzaq"
   },
   "source": [
    "### Embedding + Prediction (before PCA)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "8N7xE0W0SI5O"
   },
   "outputs": [],
   "source": [
    "data_predict = np.zeros_like(data_dim) # (p, 2)\n",
    "\n",
    "if False :\n",
    "    data_predict[:2] = data_dim[:2] + 0\n",
    "\n",
    "    tmp1 = data_dim[1] - data_dim[0]\n",
    "    tmp1 = tmp1[None].repeat(model_ld.hparams.p - 2, axis=0) # (p-2, 2)\n",
    "\n",
    "    tmp2 = data_dim[0][None].repeat(model_ld.hparams.p - 2, axis=0) # (p-2, 2)\n",
    "\n",
    "    data_predict[2:] = tmp2 + np.arange(2, model_ld.hparams.p)[..., None] * tmp1 # (p,2)\n",
    "else :\n",
    "    data_predict[0] = data_dim[0] + 0\n",
    "    data_predict[-1] = data_dim[-1] + 0\n",
    "    data_predict[1:-1] = (data_dim[:-2] + data_dim[2:]) / 2\n",
    "\n",
    "N=data_predict.shape[0] # \n",
    "filename = f\"{model.hparams.p}_structured_embedding_1\"\n",
    "#display_pca_scatterplot_simple(data_predict, words, N, filename, plot_line = True, cmap='viridis', eps = 0.01)\n",
    "\n",
    "display_pca_scatterplot_simple(data_dim, words, N, save_path, filename, \n",
    "                               #plot_line = True, \n",
    "                               plot_line = False, \n",
    "                               cmap='viridis', eps = 0.01, preicted_data_dim = data_predict,\n",
    "                               #legend_loc=\"center\",\n",
    "                               #legend_loc=\"upper center\",\n",
    "                               legend_loc=\"best\"\n",
    "                               )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "kkzN8VdMS8Gb"
   },
   "source": [
    "### Embedding + Prediction (after PCA)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "6Bzqg1JlSU8L"
   },
   "outputs": [],
   "source": [
    "data_dim_tmp = model.embeddings.weight.detach().cpu().numpy() # (p, embed_dim)\n",
    "data_predict = np.zeros_like(data_dim_tmp) # (p, embed_dim)\n",
    "\n",
    "if False :\n",
    "    data_predict[:2] = data_dim_tmp[:2]\n",
    "\n",
    "    tmp1 = data_dim_tmp[1] - data_dim_tmp[0]\n",
    "    tmp1 = tmp1[None].repeat(model_ld.hparams.p - 2, axis=0) # (p-2, embed_dim)\n",
    "\n",
    "    tmp2 = data_dim_tmp[0][None].repeat(model_ld.hparams.p - 2, axis=0) # (p-2, embed_dim)\n",
    "\n",
    "    data_predict[2:] = tmp2 + np.arange(2, model_ld.hparams.p)[..., None] * tmp1 # (p, embed_dim)\n",
    "else :\n",
    "    data_predict[0] = data_dim_tmp[0]\n",
    "    data_predict[-1] = data_dim_tmp[-1]\n",
    "    data_predict[1:-1] = (data_dim_tmp[:-2] + data_dim_tmp[2:]) / 2\n",
    "\n",
    "word_vectors = torch.from_numpy(data_predict)\n",
    "data_predict, words = display_pca_scatterplot(word_vectors.size(0), model, word_vectors = word_vectors, dim=2, return_data = True)\n",
    "\n",
    "N=data_predict.shape[0] # \n",
    "filename = f\"{model.hparams.p}_structured_embedding_2\"\n",
    "#display_pca_scatterplot_simple(data_predict, words, N, filename, plot_line = True, cmap='viridis', eps = 0.01)\n",
    "\n",
    "display_pca_scatterplot_simple(data_dim, words, N, save_path, filename, \n",
    "                               #plot_line = True, \n",
    "                               plot_line = False, \n",
    "                               cmap='viridis', eps = 0.01, preicted_data_dim = data_predict,\n",
    "                               #legend_loc=\"center\",\n",
    "                               legend_loc=\"upper center\"\n",
    "                               )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_fexQFaQTGoi"
   },
   "source": [
    "### Last layer weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "uaI4W42iSe58"
   },
   "outputs": [],
   "source": [
    "word_vectors = model.mlp[-1].weight\n",
    "data_dim, words = display_pca_scatterplot(word_vectors.size(0), model, word_vectors = word_vectors, dim=2, return_data = True)\n",
    "\n",
    "N=data_dim.shape[0]\n",
    "filename = f\"{model.hparams.p}_structured_last_layer_weights\"\n",
    "display_pca_scatterplot_simple(data_dim, words, N, save_path, filename, plot_line = False, cmap='viridis', \n",
    "                               #eps = 0.01,\n",
    "                               eps = 0.000001,\n",
    "                               )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "TccruHlkTJzk"
   },
   "source": [
    "### Last layer weights + prediction (before PCA)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "EjZpG5r8Si3t"
   },
   "outputs": [],
   "source": [
    "data_predict = np.zeros_like(data_dim) # (p, 2)\n",
    "\n",
    "if False :\n",
    "    data_predict[:2] = data_dim[:2] + 0\n",
    "\n",
    "    tmp1 = data_dim[1] - data_dim[0]\n",
    "    tmp1 = tmp1[None].repeat(model_ld.hparams.p - 2, axis=0) # (p-2, 2)\n",
    "\n",
    "    tmp2 = data_dim[0][None].repeat(model_ld.hparams.p - 2, axis=0) # (p-2, 2)\n",
    "\n",
    "    data_predict[2:] = tmp2 + np.arange(2, model_ld.hparams.p)[..., None] * tmp1 # (p,2)\n",
    "else :\n",
    "    data_predict[0] = data_dim[0] + 0\n",
    "    data_predict[-1] = data_dim[-1] + 0\n",
    "    data_predict[1:-1] = (data_dim[:-2] + data_dim[2:]) / 2\n",
    "\n",
    "N=data_predict.shape[0] # \n",
    "filename = f\"{model.hparams.p}_structured_last_layer_weights_1\"\n",
    "#display_pca_scatterplot_simple(data_predict, words, N, filename, plot_line = True, cmap='viridis', eps = 0.01)\n",
    "\n",
    "display_pca_scatterplot_simple(data_dim, words, N, save_path, filename, plot_line = False, cmap='viridis', \n",
    "                               #eps = 0.01, \n",
    "                               eps = 0.000001,\n",
    "                               preicted_data_dim = data_predict,\n",
    "                              #legend_loc=\"center\",\n",
    "                               #legend_loc=\"upper center\", \n",
    "                               legend_loc=\"best\", \n",
    "                               )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "nbFhWeMXMYSn"
   },
   "source": [
    "## Analyse embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "boc8pn-UWiDt"
   },
   "outputs": [],
   "source": [
    "from src.analyze_embedding import analyze"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "z2h6vDb1ZVY6"
   },
   "outputs": [],
   "source": [
    "save_path = os.path.join(model.hparams.log_dir, model.hparams.exp_id, \"analyse_embedding\")\n",
    "os.makedirs(save_path, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "lmBXeTshZWxt"
   },
   "outputs": [],
   "source": [
    "analyze(model, option = 1, save_path = save_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "UogjgZT0Zbu3"
   },
   "outputs": [],
   "source": [
    "analyze(model, option = 2, save_path = save_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "6FI26yY7g8uS"
   },
   "outputs": [],
   "source": [
    "analyze(model, option = 3, save_path = save_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "s1XEwq_nhjR1"
   },
   "outputs": [],
   "source": [
    "analyze(model, option = 4, save_path = save_path)"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "Train+Analyse&Visualize Embedding&decoder_layers_weights.ipynb",
   "private_outputs": true,
   "provenance": []
  },
  "gpuClass": "standard",
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
